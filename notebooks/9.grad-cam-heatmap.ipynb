{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from fastai.vision.models import Darknet\n",
    "\n",
    "\n",
    "from gradcam.misc_functions import save_class_activation_images\n",
    "from gradcam.gradcam import GradCam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get params\n",
    "target_example = 1  # Lato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(pil_im, resize_im=True):\n",
    "    \"\"\"\n",
    "        Processes image for CNNs\n",
    "\n",
    "    Args:\n",
    "        PIL_img (PIL_img): Image to process\n",
    "        resize_im (bool): Resize to 224 or not\n",
    "    returns:\n",
    "        im_as_var (torch variable): Variable that contains processed float tensor\n",
    "    \"\"\"\n",
    "    # mean and std list for channels (Imagenet)\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    # Resize image\n",
    "    if resize_im:\n",
    "        pil_im.thumbnail((512, 512))\n",
    "    im_as_arr = np.float32(pil_im)\n",
    "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
    "    # Normalize the channels\n",
    "    for channel, _ in enumerate(im_as_arr):\n",
    "        im_as_arr[channel] /= 255\n",
    "        im_as_arr[channel] -= mean[channel]\n",
    "        im_as_arr[channel] /= std[channel]\n",
    "    # Convert to float tensor\n",
    "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
    "    im_as_ten.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    im_as_var = torch.autograd.Variable(im_as_ten, requires_grad=True)\n",
    "    return im_as_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "#     get_example_params(target_example)\n",
    "\n",
    "example_list = (('/home/paperspace/code/fontastic/data/stratified/train/Lora/Lora-Regular_300_rand_crop_8.jpg', 2),\n",
    "                    ('/home/paperspace/code/fontastic/data/stratified/train/Lato/Lato-Regular_300_rand_crop_6.jpg', 1),\n",
    "                ('/home/paperspace/code/fontastic/data/stratified/train/Fahkwang/Fahkwang-BoldItalic_150_rand_crop_3.jpg', 1),\n",
    "                ('/home/paperspace/code/fontastic/data/stratified/train/Merriweather/Merriweather-Black_50_rand_crop_7.jpg', 1)\n",
    "                )\n",
    "example_index = 3\n",
    "\n",
    "img_path = example_list[example_index][0]\n",
    "target_class = example_list[example_index][1]\n",
    "file_name_to_export = img_path[img_path.rfind('/')+1:img_path.rfind('.')]\n",
    "# Read image\n",
    "original_image = Image.open(img_path).convert('RGB')\n",
    "# Process image\n",
    "prep_img = preprocess_image(original_image)\n",
    "# Define model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = Darknet([1, 2, 4, 6, 3], num_classes=6, nf=16)\n",
    "# m = nn.DataParallel(m, device_ids=None)\n",
    "\n",
    "# m.load_state_dict(torch.load('/home/paperspace/code/fontastic/notebooks/models/darknet-params'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor\"\n",
    "    def __init__(self, full:bool=False):\n",
    "        super().__init__()\n",
    "        self.full = full\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1) if self.full else x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "# num_frts = model_ft.fc.in_features\n",
    "# model_ft.avgpool.output_size = 1\n",
    "# # # model_ft.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,num_frts))\n",
    "# model_ft.fc = nn.Linear(num_frts, 6)\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_frts = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(in_features=num_frts, out_features=6)\n",
    "\n",
    "\n",
    "# m = nn.DataParallel(model_ft, device_ids=None)\n",
    "\n",
    "# m.load_state_dict(torch.load('/home/paperspace/code/fontastic/notebooks/models/darknet-params'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '/home/paperspace/code/fontastic/data/stratified/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zzz = torch.load('/home/paperspace/code/fontastic/data/stratified/model_resnet50_tfms.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(zzz.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad cam\n",
    "grad_cam = GradCam(m, target_layer=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "prep_img.to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cam mask\n",
    "cam = grad_cam.generate_cam(prep_img, target_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{file_name_to_export}-gradcam-resnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_img = f'{file_name_to_export}-gradcam-resnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_class_activation_images(original_image, cam, f'{file_name_to_export}-gradcam-resnet')\n",
    "print('Grad cam completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('../results/Merriweather-Black_50_rand_crop_7-gradcam-resnet_Cam_On_Image.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

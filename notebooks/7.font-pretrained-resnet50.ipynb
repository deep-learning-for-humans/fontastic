{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fontastic/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "from models.lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import transform as tfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating image datasets an data loaders for train and test using the experiments folder split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = '/home/paperspace/code/fontastic/data/stratified/'\n",
    "data_path = '/home/paperspace/code/fontastic/data/dst/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rand_tfms = tfm.get_transforms(do_flip=False)\n",
    "test_rand_tfms = tfm.get_transforms(do_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "\n",
    "        transforms.RandomAffine(degrees=5, fillcolor=(255, 255, 255)),\n",
    "        transforms.ColorJitter(brightness=(1, 1.2), contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]), \n",
    "    'test' : transforms.Compose([\n",
    "\n",
    "        transforms.RandomAffine(degrees=5, fillcolor=(255, 255, 255)),\n",
    "        transforms.ColorJitter(brightness=(0.8, 1.2), contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_files_path(experiments_path, data_path, phase):\n",
    "    if phase == 'train':\n",
    "        file_name = 'train.csv'\n",
    "    elif phase == 'test':\n",
    "        file_name = 'test.csv'\n",
    "    else:\n",
    "        print(\"phase can only have train and test as parameter values\")\n",
    "        exit()\n",
    "    file_path = os.path.join(experiments_path, file_name)\n",
    "    train_df = pd.read_csv(file_path, delimiter=',')\n",
    "    files_path = []\n",
    "    fonts_class = []\n",
    "    for row in train_df.iterrows():\n",
    "        files_path.append(os.path.join(data_path, row[1]['class'], row[1]['filename']))\n",
    "        fonts_class.append(row[1]['class'])\n",
    "    \n",
    "    return files_path, fonts_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_path(file_path, file_class, destination_dir):\n",
    "    font_folder = os.path.join(destination_dir, file_class)\n",
    "    if os.path.exists(font_folder) == False:\n",
    "        os.makedirs(font_folder)\n",
    "    \n",
    "    print(\"File being copied from {}:{}\".format(file_path, font_folder))\n",
    "    shutil.copy(file_path, font_folder)\n",
    "    #shutil.copyfile(file_path, font_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/paperspace/code/fontastic/data/stratified/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4c5c6cfa9c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_files_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiments_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_files_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiments_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0ad87ff94bc3>\u001b[0m in \u001b[0;36mget_train_files_path\u001b[0;34m(experiments_path, data_path, phase)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiments_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfiles_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfonts_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fontastic/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fontastic/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fontastic/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fontastic/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fontastic/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/home/paperspace/code/fontastic/data/stratified/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# X_train, y_train = get_train_files_path(experiments_path, data_path, phase='train')\n",
    "# X_test, y_test = get_train_files_path(experiments_path, data_path, phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dir = os.path.join(experiments_path, 'train')\n",
    "# test_dir = os.path.join(experiments_path, 'test')\n",
    "\n",
    "# if not os.path.exists(train_dir):\n",
    "#     os.makedirs(train_dir)\n",
    "\n",
    "# if not os.path.exists(test_dir):\n",
    "#     os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_path, font_class in zip(X_train, y_train):\n",
    "#     copy_images_to_path(file_path, font_class, train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_path, font_class in zip(X_test, y_test):\n",
    "#     copy_images_to_path(file_path, font_class, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(experiments_path, x), data_transforms[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 999\n",
       "     Root Location: /home/paperspace/code/fontastic/data/stratified/train\n",
       "     Transforms (if any): Compose(\n",
       "                              RandomAffine(degrees=(-5, 5), fillcolor=(255, 255, 255))\n",
       "                              ColorJitter(brightness=(1, 1.2), contrast=[0.9, 1.1], saturation=[0.9, 1.1], hue=[-0.1, 0.1])\n",
       "                              ToTensor()\n",
       "                              Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "                          )\n",
       "     Target Transforms (if any): None, 'test': Dataset ImageFolder\n",
       "     Number of datapoints: 250\n",
       "     Root Location: /home/paperspace/code/fontastic/data/stratified/test\n",
       "     Transforms (if any): Compose(\n",
       "                              RandomAffine(degrees=(-5, 5), fillcolor=(255, 255, 255))\n",
       "                              ColorJitter(brightness=(0.8, 1.2), contrast=[0.9, 1.1], saturation=[0.9, 1.1], hue=[-0.1, 0.1])\n",
       "                              ToTensor()\n",
       "                              Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "                          )\n",
       "     Target Transforms (if any): None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                             batch_size=32, \n",
    "                                             shuffle=True, \n",
    "                                             num_workers=3) \n",
    "               for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f98b1533b70>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f98b1533a58>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fahkwang', 'Lato', 'Lobster', 'Lora', 'MajorMonoDisplay', 'Merriweather']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(inp)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "out = torchvision.utils.make_grid(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=20):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    new_freeze_state = None\n",
    "    prev_freeze_state = False\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "#                 scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "        \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc:{:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            \n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "num_frts = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_frts, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-03, weight_decay=1e-02)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model_ft.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a05c9c118e546dd886a3cd6f021ada2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=1e-7, weight_decay=1e-2)\n",
    "lrf = LRFinder(model_ft, optimizer, criterion, device=\"cuda\")\n",
    "lrf.range_test(dataloaders['train'], end_lr=100, num_iter=100, step_mode=\"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEOCAYAAABmVAtTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcXFWd///Xp6r3PenurCQkZCGEBIJpNtmiIKKCAWQQRkBEJiLOCMLM4FdndEbHr9sMXwb5YoiCyA8U2WRRhEEBI0KADoQlCWQDsnQn3Z30vi+f3x9VafIN3Ul30rduVfX7+XjUI7dunar7Oanu++lzzz3nmLsjIiICEAk7ABERSR5KCiIi0k9JQURE+ikpiIhIPyUFERHpp6QgIiL9lBRERKSfkoKIiPRTUhARkX5KCiIi0i8j7ACGq6yszKdNmxZ2GCIiKWXlypV17l6+v3IplxSmTZtGZWVl2GGIiKQUM3tvKOV0+UhERPopKYiISD8lBRER6aekICIi/ZQURESkn5KCiIj0U1IQEUkBT63ZwYaalsCPo6QgIpLk3J2r71nJg69sDfxYgSUFM5tiZs+Y2VozW21m1wxSbpGZrYqX+XNQ8YiIpKr6tm66e51xhdmBHyvIEc09wPXu/oqZFQIrzewpd1+zu4CZlQC3Ame5+2YzGxdgPCIiKammuQOAcYU5gR8rsJaCu1e7+yvx7WZgLTB5r2J/Czzk7pvj5WqCikdEJFXtaOoEYFxR8C2FhPQpmNk04Bjgxb1emg2MMbNnzWylmV2WiHhERFJJTdPulkJqXz4CwMwKgAeBa929aYDjLwROB3KBF8xshbuv2+szlgBLAKZOnRp0yCIiSaWmOd5SSOXLRwBmlkksIdzj7g8NUGQr8IS7t7p7HbAcOHrvQu6+zN0r3L2ivHy/M7+KiKSV2uZOCnMyyM2KBn6sIO8+MuB2YK273zhIsUeAU8wsw8zygOOJ9T2IiEjcjqaOhFw6gmAvH50EXAq8YWar4vu+AUwFcPel7r7WzJ4AXgf6gJ+7+5sBxiQiknJqmjsTcukIAkwK7v4cYEMo92Pgx0HFISKS6mqaO1g4dUxCjqURzSIiSczdqWnqZFxRYloKSgoiIkmsqaOHzp6+hPUpKCmIiCSx3WMUypUURERk9xiF8bp8JCIi7897pJaCiMioV9M/75FaCiIio96Opk7ysqIUZAc+KxGgpCAiktRqmjsS1p8ASgoiIkmtprkzYXcegZKCiEhSq23uTFgnMygpiIgktZqmjoTNewRKCiIiSauls4fWrt6ErLi2m5KCiEiS2j2aebySgoiIJHLFtd2UFEREktT7SUEtBRGRUW/35SO1FEREhJrmTrIzIhTlJmY0MygpiIgkrZqmDsYVZRNb8j4xlBRERJJUItdm3i2wpGBmU8zsGTNba2arzeyafZQ91sx6zeyCoOIREUk1NQkezQzBthR6gOvd/QjgBOArZjZ370JmFgV+CDwZYCwiIilnR1NiJ8ODAJOCu1e7+yvx7WZgLTB5gKL/ADwI1AQVi4hIquno7qW5oyehk+FBgvoUzGwacAzw4l77JwPnAUsTEYeISKroX1wn3ZKCmRUQawlc6+5Ne718E3CDu/fu5zOWmFmlmVXW1tYGFaqISNLoX4YzwZePAr351cwyiSWEe9z9oQGKVAD3xm+3KgM+aWY97v7wnoXcfRmwDKCiosKDjFlEJBnsHs2cyHmPIMCkYLEz/e3AWne/caAy7j59j/J3Ar/bOyGIiIxGO0IYzQzBthROAi4F3jCzVfF93wCmAri7+hFERAZR09xJZtQYk5eZ0OMGlhTc/TlgyMPw3P3yoGIREUk1NU2dlBckdjQzaESziEhSqmnuoDzBncygpCAikpRqmjoZn+DbUUFJQUQkKdU0dyR0Gc7dlBRERJJMV08f9W3dCb/zCJQURESSTm1LOKOZQUlBRCTp7F5xLdGT4YGSgohI0tkRn/co0ZPhgZKCiEjSqe2f90hJQURk1Ktp7iRiUJqvpCAiMurVNHVSXphNNJLY0cygpCAiknR2NHeEcjsqKCmIiCQVd2dDTQsTi5UURERGvVe3NLC1vp2PzR0fyvGVFEREksjDr24jOyPCWfMmhHJ8JQURkSTR1dPHY69VceaREyjMSew6CrspKYiIJInl62qpb+vmvGMmhRaDkoKISJL47aptlOZnccqs8tBiUFIQEUkCTR3dPLVmB+ccPYnMaHinZiUFEZEk8MQb2+nq6ePcYyaHGkdgScHMppjZM2a21sxWm9k1A5T5nJm9Hn88b2ZHBxWPiEgy++2r25hels/RhxSHGkeQLYUe4Hp3PwI4AfiKmc3dq8w7wGnufhTwXWBZgPGIiCSlqoZ2Vryzk/OOmYxZ4qe22FNGUB/s7tVAdXy72czWApOBNXuUeX6Pt6wADgkqHhGRZPXIqirc4dwF4V46ggT1KZjZNOAY4MV9FPsi8IdExCMikizcnd++upWFh45hamle2OEEnxTMrAB4ELjW3ZsGKfMRYknhhkFeX2JmlWZWWVtbG1ywIiIJtqa6iXU7Wjgv5A7m3QJNCmaWSSwh3OPuDw1S5ijg58Bid985UBl3X+buFe5eUV4e3v27IiIj7ZFVVWRGjU/Nnxh2KECwdx8ZcDuw1t1vHKTMVOAh4FJ3XxdULCIiyWr5ulqOmz6WMflZYYcCBNjRDJwEXAq8YWar4vu+AUwFcPelwLeAUuDWeI97j7tXBBiTiEjS2NXaxVvbm/nHM2eHHUq/IO8+eg7Y571V7n4lcGVQMYiIJLOX3oldMT9xRmnIkbxPI5pFRELywsad5GZGmT+5JOxQ+ikpiIiEZMWmXVRMG0NWRvKcipMnEhGRUWRnSydv72jmhMOS59IRKCmIiIRixaZdQHL1J4CSgohIKFZs2kleVpT5k8OdAG9vSgoiIiF4YdNOjp02NtS1EwaSXNGIiIwCtc2dbKhpSbpLR6CkICKScCs2xcYnJFsnMygpiIgk3IpNOynIzmDepKKwQ/kAJQURkQSL9SeMISPJ+hNASUFEJKF2NHWwqbY1KfsTQElBRCShkrk/AZQUREQSasWmnRRmZ3DkpOQan7CbkoKISAKt2LSL46aPJRrZ5yTSoVFSEBFJkO2NHbxTl7z9CaCkICKSMMnenwBKCiIiCfPchjqKczM5YmLyjU/YTUlBRCQB3J3n1tdx0szSpO1PACUFEZGE2FjbwvamDk6eWR52KPsUWFIwsylm9oyZrTWz1WZ2zQBlzMxuNrMNZva6mX0oqHhERML0l/V1AJwyqyzkSPYtI8DP7gGud/dXzKwQWGlmT7n7mj3KfAKYFX8cD/w0/q+ISFp5bn0dh5bmMWVsXtih7FNgLQV3r3b3V+LbzcBaYPJexRYDd3nMCqDEzCYGFZOISBi6e/tYsWknJ89M7lYCJKhPwcymAccAL+710mRgyx7Pt/LBxCEiktJe3dxAa1dv0l86ggQkBTMrAB4ErnX3pr1fHuAtPsBnLDGzSjOrrK2tDSJMEZHAPLe+lojBiTPSJCmY2Qwzy45vLzKzr5pZyRDel0ksIdzj7g8NUGQrMGWP54cAVXsXcvdl7l7h7hXl5cndcy8isre/bKjjqENKKM7NDDuU/RpqS+FBoNfMZgK3A9OBX+3rDWZm8bJr3f3GQYo9ClwWvwvpBKDR3auHGJOISNJrbO/mtS0NnJoCl45g6Hcf9bl7j5mdB9zk7j8xs1f3856TgEuBN8xsVXzfN4CpAO6+FHgc+CSwAWgDvjDcCoiIJLMXNu6kz+HkWalxlWOoSaHbzC4GPg+cE9+3z3aQuz/HwH0Ge5Zx4CtDjEFEJOU8t6GW/Kwox0zd7xX3pDDUy0dfAE4Evufu75jZdODu4MISEUkPf1lfxwmHlZKZhEtvDmRILYX4gLOvApjZGKDQ3X8QZGAiIqluy6423tvZxuUfnhZ2KEM21LuPnjWzIjMbC7wG/MLMBus8FhERUmdqiz0NtT1THB9jcD7wC3dfCJwRXFgiIqnvuQ21TCjKYUZ5QdihDNlQk0JGfPqJC4HfBRiPiEha6O1z/rphJyfPKiN2h35qGGpS+A7wJLDR3V82s8OA9cGFJSKS2t7Y1khje3dKXTqCoXc03w/cv8fzTcBnggpKRCTVPfzqNrKiEU5NkfEJuw21o/kQM/utmdWY2Q4ze9DMDgk6OBGRVNTZ08vDq7bxsSPHMyY/K+xwhmWol49+QWxKiknEZjF9LL5PRET28tSaHTS0dfPZiin7L5xkhpoUyt39F+7eE3/cCaRWm0hEJEF+8/IWJpfkpsT6CXsbalKoM7NLzCwaf1wC7AwyMBGRVLS1vo3nNtRxwcJDiERS566j3YaaFK4gdjvqdqAauABNXici8gEPrNwKwAULU7PbdUhJwd03u/un3b3c3ce5+7nEBrKJiEhcX59zf+VWTppRlvRrMQ/mYGZoum7EohARCVBjezf/8vAbPPpaFR3dvYEd5/mNO9nW0M6Fx6ZeB/NuQ506eyCpd7FMREalv6yv5e4Vm7l7xWYKczI45+hJXLDwEI6ZUjKio41/U7mF4txMzpw7fsQ+M9EOJil8YC1lEZFkVN3QAcBtly7kiTe389ArW/nVi5uZVprHSTPLOHFGKSccVkpZQfYBH6OhrYsnV2/n4mOnkJMZHanQE26fScHMmhn45G9AbiARiYiMsKrGdvKzopw5dzwfP3IC31l8JI+/Uc0f3tzOw69u454XNwMwa1wBZ8wdz5UnT6d0mAnikVVVdPX0pfSlI9hPUnD3wkQFIiISlOqGDiaW5PZfKirMyeSzx07ls8dOpae3jze2NfLCpp28sHEnt/15I798/l2uOGk6f3fKYRTnvb/I5K7WLp54cztPrt5Onzvji3KYWJzD+KIc7l7xHvMmF3HkpOKwqjkiDubykYhISqhubGdicc6Ar2VEIxwzdQzHTB3D1YtmsqGmhZv+uI5bntnAL194l7875TAmFOXw2OtVPL9xJ719zrTSPIpzM1m3o5na5k764tdTvnfevMRVKiCBJQUzuwM4G6hx9w/8T5lZMbElPafG4/hPd9fUGSIy4qoaO5gzoWhIZWeOK+CWv/0QX/lIEzc+tY4bn1oHwJSxuSw59TDOPmoicycW9bc6enr7qGvpor6ti8PHp/7FlSBbCncCtwB3DfL6V4A17n6OmZUDb5vZPe7eFWBMIjLKdPX0UdfSycSSgVsKgzliYhE/u6yCt7Y30d3jzJtcNOCdShnRCBOKc5gwSEsk1QSWFNx9uZlN21cRoNBi/8sFwC6gJ6h4RGR02tHUgTtMKj6we2OG2sJIF2H2KdxCbObVKqAQ+Ky794UYj4ikoaqGdoBhtxRGq4MZ0XywPg6sIjYd9wLgFjMbMCWb2RIzqzSzytra2kTGKCIprroxNkZh4gG2FEabMJPCF4CHPGYD8A4wZ6CC7r7M3SvcvaK8XDN2i8jQVTXGWgqT1FIYkjCTwmbgdAAzGw8cDmwKMR4RSUPVDR0U52aSl6U78IciyFtSfw0sAsrMbCvwbSATwN2XAt8F7jSzN4iNkL7B3euCikdERqd9jVGQDwry7qOL9/N6FXBmUMcXEYFYn8KkEvUnDFWYl49ERAJX3dihlsIwKCmISNrq6O5lV2uXWgrDoKQgImnr/dtR1VIYKiUFEUlb1bsHrmmMwpApKYhI2qqKtxQ0RmHolBREJG3tbimky2R1iaCkICJpq6qxg7KCLLIzUnd5zERTUhCRtFXd2K5WwjApKYhI2qpu6FAn8zApKYhI2qpqbGeSWgrDoqQgImmppbOH5o4eJmrg2rAoKYhIWnp/jIJaCsOhpCAiaen9MQpqKQyHJhhPAHens6ePju5e2rt7ae3sYVdrN7taO/v/be/uxTDMYvOIY0ZBdpSx+dmUFmRRmp9FaUE2Y/Iyyc2MDriAuIi8Ty2FAzOqk0J3bx/1bV309jm9fU5fH/S60+eOe+xk7oA7NHd0U9PcSW1zJzXNHdQ1dwGQkxkhOzNKTkaEaCRCfVsXNc0d7GiKldvZ0kV7dy/u+44lGomd5N2dvv2UzcqIMCYvkzF5WRTlZpKfFSUnM0puZpTszCh5WVFKcjMpyc+iJDdWriQvk7H5WYzNzyInU/dsS/qrauzADMYXKSkMx6hJCqurGnlw5TaqG9upauyguqGd2pbO/Z6sBxKNGGPzs4gYdHT30dnTS0d3HwCF2RmUF2UzvjCHD00dQ1lBNvlZsZN1bmaU3KzYSXv3CXpsfhZj8j54onZ3Wrt62dnSSV1LF7tau9jZ0kl9WzcNbV3Ut3VR39ZNY1s3dfHE0xF/tHbGWiSDyc2MHX98UTYzxxW8/ygvZFJJDhlRXVWU1Ffd0M64wmwy9fM8LKMmKVQ1dHDvy5uZWJzDpJJcDj+8nInFuZQVZJERjRA1IxIxohGIxC/NRGz35RyjICeD8oJsxhVlMyYvq/8v+93cnZ4+H7EfQDOjIDuDguwMDi3NH/b7O3t6aWzvpqEt9tjV2kVDWxe72rqob+1iZ2sX2+rbefqtGu6r3Nr/vohBWUE2E4pzGFeYw4TibMbmZ8daHPmZlORmMSY/i2mleZTkZY1IXUWCEFtHQf0JwzVqksLpc8ax+t8/Hti1eDMjM5o81/mzM6KMK4wyrnD/TeeGti421LSwoaaFbQ3t7GjqYHtTJ1vr26h8bxeN7d0DtqjG5mcxozyfGeUFzBpfyEkzSzl8fKH6OyQpVDW2M2dCYdhhpJxRkxQiEZ2oBlOSl0XFtLFUTBs74Ou9fU5TezcN7d3Ut3Wxs6WLd+ta2VjbwqbaVp5as4N7X94CwPiibE6ZVc6ps8s5dVaZWhMSCnenuqGDjxw+LuxQUs6oSQpy4KIRY0x+7LLRdAa+lFXd2M5f1tXx53W1PLVmBw+s3EpGxDh1djmLF0ziY3PHk5elHzdJjMb2btq7e3Xn0QEI7LfUzO4AzgZq3H3eIGUWATcBmUCdu58WVDwSrInFuVx47BQuPHYKvX3Oqi0N/M/q7Tz6WhVPv1VDXlaUM+eO528qpvDhGaW6xCSBqmrQGIUDFeSfbncCtwB3DfSimZUAtwJnuftmM1M7L01EI8bCQ8ew8NAx3HDWHF56dxePrKri8TeqeXhVFXMmFHLlKYfx6aMnkZWhO0Nk5FU3aozCgQrsN9LdlwO79lHkb4GH3H1zvHxNULFIeCIR44TDSvn++fN56Zun86MLjqLPnX+8/zVO/uHT/N9nNtDQ1hV2mJJmNJr5wIX5Z9psYIyZPWtmK83sssEKmtkSM6s0s8ra2toEhigjKTsjyoUVU3jy2lP55RXHMXt8IT9+8m2O/99/4p/uf403tjaGHaKkieqGdjIiRllBdtihpJwwe/4ygIXA6UAu8IKZrXD3dXsXdPdlwDKAioqKAxhuJsnEzDhtdjmnzS5nbXUTd73wHg+/uo37V25lwZQSLjvxUD511EStliUHrLqxg/FFOR8YTyT7F2ZLYSvwhLu3unsdsBw4OsR4JARHTCzi++fPZ8U3TudbZ8+lqb2b6+57jZN+8DQ3/s/b7GjqCDtESUFVDe1MKlF/woEIMyk8ApxiZhlmlgccD6wNMR4JUXFuJlecPJ0/Xncad11xHEcfUsJPntnAST94mmvufZVXN9eHHaKkEI1mPnBB3pL6a2ARUGZmW4FvE7v1FHdf6u5rzewJ4HWgD/i5u78ZVDySGiLxsQ2nzi7n3bpWfvnCu9xfuZVHVlWx6PByvv6JOcyZUBR2mJLE+vqc7Y0dTJyvlsKBMD+QGeFCVFFR4ZWVlWGHIQnU0tnD3Sve49ZnNtDc2cMFHzqE686crb8EZUAbapo548bl/Punj+TzH54WdjhJw8xWunvF/srpJnFJegXZGVx12gyW//NHuPLk6bFWw4+f5UdPvEVbV0/Y4UkS6e1zbnjwDQpzMvj4kRPCDiclKSlIyijJy+Kbn5rLn64/jU/Mm8Ctz27k4zct57n1dWGHJkli2fJNrHyvnu8sPpIJGrh2QJQUJOVMGZvHTRcdw2+WnEBmJMIlt7/IP93/mgbBjXJrq5u48am3+eT8CZy7YHLY4aQsJQVJWccfVsrj15zC1Ytm8NCr2zjjxuU8/kZ12GFJCDp7evnab1ZRnJvFf5w7X3NrHQQlBUlpOZlR/vmsOTz29yczsTiHq+95hevuW0VLp/oaRpP/89R63trezI8umM/YfE3XfjA0l7GkhbmTivjt1R/m5qc3cMvT66l8t56bLlrAh6aOCTs0GUFbdrWxprrp/eVs87JYX9PCbcs3cvFxU/jonPFhh5jylBQkbWREI1z3sdmcMquMa+9dxd8sfYFrTp/FVz4yU9MdpIH3drZyzk+eo6njg63AKWNz+ean5oYQVfpRUpC0c+y0sTx+zSn868NvcuNT63j53V387LIKcjI1l1Kqau3sYcldK4lEjHuuPJ7ePmdXaxe7WrtobO9m8YJJFGTrdDYS9L8oaak4N5ObLz6GE2eU8r8eeoO//9Ur/PSShWRG1Y2Watydf3rgNdbXNPPLK47jpJllYYeU1vQbImnt4uOm8t1z5/HHtTV87Ter6O1LrRH8Aj/980Yef2M7N5w1h1NmlYcdTtpTS0HS3qUnHEpbZw/f/8Nb5Gdl8P3z5xNRH0NKePbtGn785Nucc/Qklpx6WNjhjApKCjIqfOm0GbR29nDz0xvIy47yrbPn6l72JPduXStf/fWrHD6+kB9+RmMPEkVJQUaNr31sNi2dvdzx13fIikb4+ifm6ESTpJ54cztff+h1IhHjZ5dVkJelU1Wi6H9aRg0z41/PPoLu3j5uW76J+rYu/vd588lQ53PSaOvq4TuPreHel7cwf3Ix/33RAqaMzQs7rFFFSUFGFTPjO4uPZGx+Fv/9p/XUt3Xzk4uP0e2qCdLU0c3K9+p5e3szZQXZTBmTy5SxeYwvymF1VSPX3ruKd3a28uVFM/jaGbPJylDCTjQlBRl1zIyvfWw2Y/Oz+LfHVnPZHS/x889XUJSTGXZoaaGzp5f61u7+cQQ1zR28tqWBl96t563tTQy0hEtm1OhzGFeYza+uPIETZ5QmPnABlBRkFPv8h6cxJj+L6+9bxWdvW8FdVxxHeWF22GGlrMb2bi69/UVe39r4gdfysqJ8aOoYrjl9FsdNG8uRk4upb+1iS30bW3a1s6W+DYAvnXoYJXmauyhMSgoyqn366EmMyctkyV0rueyOl/jNl05Qi+EA9PU519+3ijVVTfzDR2cyoTiHsXmx+YlKC7I4tDT/AwMHi3MzmVaWH1LEMhglBRn1TplVzm2XLuSKO19myV2V3PmF49THMEy3PruBP66t4dvnzOULJ00POxw5CIH14pjZHWZWY2Zv7qfcsWbWa2YXBBWLyP6cOruc/7rwaFZs2sW192rk83D8eV0t//XUOhYvmMTlWhM55QXZtX8ncNa+CphZFPgh8GSAcYgMyeIFk/nXs+fyxOrt/Osjb+ID9YjK/2PLrjauuTc2wOz752uAWToI7PKRuy83s2n7KfYPwIPAsUHFITIcXzx5OrXNnSz980bGFWZz7Rmzww4paXV09/Lle1bS2+csvWShBpilidC+RTObDJwHfJT9JAUzWwIsAZg6dWrwwcmodsNZh1Pb3MlNf1xPn8PXzpilv4D30t7Vy/X3r+LNbU3c/vkKdRinkTBT+03ADe7eu79fOHdfBiwDqKioUJteAmVm/OAz8zGDm/+0nq31bfzg/KM0kCrunbpWvnz3St7e0cw3P3kEpx+h1c7SSZhJoQK4N54QyoBPmlmPuz8cYkwiAGRGI/z4gqOYOjaPG59aR3VDB0svXUhx7ui+XfWJN6v5p/tfJxo17vzCcZw2W1NZp5vQ/vRx9+nuPs3dpwEPAFcrIUgyMTO+evosbrzwaCrf28UFP32erfFBVqNNd28f3/v9Gq66+xUOG1fA7796ihJCmgqspWBmvwYWAWVmthX4NpAJ4O5LgzquyEg7/0OHMKE4hy/9fys579bnuXfJCcwoLwg7rMA1dXSzfF0tT79Vw5/frmVnaxeXnXgo3/zUEWRnaBxHurJUu+2uoqLCKysrww5DRqH1O5q5+GcryIxGuO9LJ6bt7J1vbmvke79fy8vv7qKnzynJy2TR7HIWL5jMR+aMCzs8OUBmttLdK/ZbTklBZOjWVjdx0bIVFOdmcv9VJzK+KCfskEbUxtoW/mbpC2REjM8sPITT54xjwZQSTS+eBoaaFPRNiwzDEROL+OUVx7GzpZPP/fxFdrZ0hh3SiKlubOey21/CgN986URuOGsOFdPGKiGMMvq2RYZpwZQS7rj8WLbWt3Hp7S/R2N4ddkgHraGti8vidfnlFccxXeMORi0lBZEDcPxhpdx2aQXra5r525+tYE1VU9ghHbC2rh6+cOfLvLezjWWXLWTe5OKwQ5IQKSmIHKDTZpez9JKFVDd2cPZP/sK/Pbo65VoN3b19fPnuV3htSwM3X7yAD88oCzskCZmSgshBOP2I8Txz/SIuOeFQ7nrhXT76n89yX+UW+lJkltXbn3uHP6+r5bvnzuOseRPDDkeSgJKCyEEqzsvkO4vn8ejfn8yhpXn88wOvc/U9ryT9LKvVje3c/Kf1nHHEeD53/KFhhyNJQklBZITMm1zMA1d9mH88czZPrN7Or17aHHZI+/Qfv19Lb5/z7XPmhh2KJBElBZERFIkYVy+aySmzyviP363l3brWsEMa0HPr6/j969VcvWhm2g7CkwOjpCAywiIR40cXHEVG1Lj+/teSbhW3rp4+vv3om0wdm8eXTjss7HAkySgpiARgYnEu3108j5Xv1XPb8o1hh/P/+MVf32FjbSv/9um5WotaPkBJQSQgixdM4lPzJ/J/nlqXNOMYqhvb+e8/reeMI8bx0TlaB0E+SElBJCBmxnfPnUdJXhbX3beKzp7eUONx9z06l48MNRZJXlpUVSRAY/Oz+OFn5nPFnZWc9IOnKc3Ppig3g+LcTApzMunu7aO9q5fWrh7au3rJiEb4t3OOZP4hIzuquKO7l395+E1+/3o1XztjtjqXZVCaJVUkAe6v3MJL7+yisb2bpo5umtp7aO4R6Sz+AAAJEUlEQVTsJjMSITcrSl5WlNysDN6qbqKnz7nvSycyc9zIrNmweWcbV929kjXVTXz19Flcc/osohGtOT3aaOpskRT0Tl0rf7P0eTKjER748oeZXJJ7UJ/3zFs1XPubVbg7N120QP0Io5iSgkiKWl3VyEXLVlBekM19V51IWUH2ft/j7jS2d1PV0EF1YztVDe2sqW7m3pc3c8SEIpZespCppbpkNJoNNSmoT0EkyRw5qZhfXH4sl9z+Ip+/4yV+veQEcjKivLK5nr9uqOMv6+vYWNNCT5/T605vnw84FiIzaly4cAr/vvhI3XoqQ6aWgkiSevbtGv7urkrGFeZQ39ZFW1cv0Yhx9CHFzJ9cTFZGhGgkQkbEiESMopwMJpXkMrE4h8kluZQVZBNR34HEhd5SMLM7gLOBGnefN8DrnwNuiD9tAb7s7q8FFY9Iqll0+Dj++6Jj+L/PbOCjc8Zx8qwyTpxRSlFOZtihSRoL8vLRncAtwF2DvP4OcJq715vZJ4BlwPEBxiOScj45fyKfnK8prSVxAksK7r7czKbt4/Xn93i6AjgkqFhERGRokmVE8xeBP4QdhIjIaBf63Udm9hFiSeHkfZRZAiwBmDp1aoIiExEZfUJtKZjZUcDPgcXuvnOwcu6+zN0r3L2ivLw8cQGKiIwyoSUFM5sKPARc6u7rwopDRETeF+Qtqb8GFgFlZrYV+DaQCeDuS4FvAaXArWYG0DOUe2hFRCQ4Qd59dPF+Xr8SuDKo44uIyPAly91HIiKSBFJumgszawTW77GrGGgc5Pnu7T33lQF1BxHC3scbbrmB9u9v31C2E1GvfZUZSr2G8l3tuR32dzXYa6ler6Hu18/gwddpsLiGU2ak6nWou+//Th13T6kHsGyoz3dv77WvciSPP9xyA+3f374hbgder32VGUq9hvJd7fW9hfpdpWu9hrpfP4MHX6dkq9dQHql4+eixYTx/bJAyI3n84ZYbaP/+9g1l+2AN5bP2VWYo9RrKdzXUWIbiYL+rwV5L9XoNdb9+BkdGMtVrv1Lu8tHBMrNKT8O7nNKxXulYJ1C9Ukk61ml/UrGlcLCWhR1AQNKxXulYJ1C9Ukk61mmfRl1LQUREBjcaWwoiIjIIJQUREemnpCAiIv2UFPZgZhEz+56Z/cTMPh92PCPBzBaZ2V/MbKmZLQo7npFkZvlmttLMzg47lpFiZkfEv6sHzOzLYcczEszsXDP7mZk9YmZnhh3PSDGzw8zsdjN7IOxYRlLaJAUzu8PMaszszb32n2Vmb5vZBjP7+n4+ZjEwGegGtgYV61CNUJ2c2BrYOSRBnWDE6gWxNb7vCybK4RuJern7Wne/CrgQCP1WyBGq08Pu/nfA5cBnAwx3yEaoXpvc/YvBRpp4aXP3kZmdSuzkd5e7z4vviwLrgI8ROyG+DFwMRIHv7/URV8Qf9e5+m5k94O4XJCr+gYxQnercvc/MxgM3uvvnEhX/YEaoXkcRm4Igh1gdf5eY6Ac3EvVy9xoz+zTwdeAWd/9VouIfyEjVKf6+/wLucfdXEhT+oEa4XqGfK0ZS6CuvjRQfeE3o44AN7r4JwMzuJbagz/eBD1xyiE/x3RV/2htctEMzEnXaQz2QHUScwzVC39VHgHxgLtBuZo+7e1+gge/HSH1f7v4o8KiZ/R4INSmM0HdlwA+APyRDQoAR/91KK2mTFAYxGdiyx/OtwPH7KP8Q8BMzOwVYHmRgB2FYdTKz84GPAyXALcGGdlCGVS93/yaAmV1OvDUUaHQHbrjf1yLgfGIJ/PFAIztww/29+gfgDKDYzGZ6bD2VZDTc76oU+B5wjJn9r3jySHnpnhRsgH2DXi9z9zZi60Uns+HW6SFiyS7ZDate/QXc7xz5UEbUcL+vZ4FngwpmhAy3TjcDNwcXzogZbr12AlcFF0440qajeRBbgSl7PD8EqAoplpGSjnUC1SuVpGOdIH3rNSzpnhReBmaZ2XQzywIuAh4NOaaDlY51AtUrlaRjnSB96zUsaZMULLYm9AvA4Wa21cy+6O49wN8DTwJrgfvcfXWYcQ5HOtYJVK9Uqlc61gnSt14jIW1uSRURkYOXNi0FERE5eEoKIiLST0lBRET6KSmIiEg/JQUREemnpCAiIv2UFCRtmFlLgo/3czObm+BjXmtmeYk8powuGqcgacPMWty9YAQ/LyM+oClh4jOK2mAT/JnZu0CFu9clMi4ZPdRSkLRmZuVm9qCZvRx/nBTff5yZPW9mr8b/PTy+/3Izu9/MHgP+x2Ir1z1rsZXQ3jKze+InbuL7K+LbLRZbte81M1sRX78CM5sRf/6ymX1noNaMmU0zs7VmdivwCjDFzH5qZpVmttrM/j1e7qvAJOAZM3smvu9MM3vBzF6Jxz1iSVFGKXfXQ4+0eAAtA+z7FXByfHsqsDa+XQRkxLfPAB6Mb19ObGK0sfHni4BGYpOjRYhNjbD7854l9lc7xGbTPCe+/SPgX+LbvwMujm9fNUiM04A+4IQ99u0+fjR+nKPiz98FyuLbZcSmeM+PP78B+FbY34Meqf1I96mzRc4A5sb/uAcoMrNCoBj4pZnNInZCz9zjPU+5+649nr/k7lsBzGwVsZP4c3sdp4tYAgBYSWz1LoATgXPj278C/nOQON9z9xV7PL/QzJYQm95+IrHFhF7f6z0nxPf/NV6/LGJJS+SAKSlIuosAJ7p7+547zewnwDPufl58Ba5n93i5da/P6Nxju5eBf2+63d33U2Zf+o9pZtOBfwSOdfd6M7uT2LKjezNiCeziYR5LZFDqU5B09z/EZr4EwMwWxDeLgW3x7csDPP4K4DPx7YuG+J4iYkmiMd438Yk9XmsGCvf47JPMbCaAmeWZ2eyDD1lGMyUFSSd58WmQdz+uA74KVJjZ62a2hvdXyvoR8H0z+yux6/ZBuRa4zsxeInYZqHF/b3D314BXgdXAHcBf93h5GfAHM3vG3WuJJbRfm9nrxJLEnJENX0Yb3ZIqEqD4mIJ2d3czu4hYp/PisOMSGYz6FESCtRC4JX4bawNwRcjxiOyTWgoiItJPfQoiItJPSUFERPopKYiISD8lBRER6aekICIi/ZQURESk3/8PXv9I9iSEMVgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "\n",
    "num_frts = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_frts, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-03, weight_decay=1e-02)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "train Loss: 1.4014 Acc:0.4685\n",
      "\n",
      "test Loss: 1.1405 Acc:0.5600\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "train Loss: 0.9521 Acc:0.6126\n",
      "\n",
      "test Loss: 433.0719 Acc:0.3960\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "train Loss: 0.9702 Acc:0.6076\n",
      "\n",
      "test Loss: 0.9965 Acc:0.6120\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "train Loss: 0.6786 Acc:0.7287\n",
      "\n",
      "test Loss: 2.2418 Acc:0.3600\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "train Loss: 0.6702 Acc:0.7377\n",
      "\n",
      "test Loss: 1.0157 Acc:0.5920\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "train Loss: 0.4778 Acc:0.8228\n",
      "\n",
      "test Loss: 3.1915 Acc:0.1920\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "train Loss: 0.4408 Acc:0.8338\n",
      "\n",
      "test Loss: 1.0038 Acc:0.4880\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "train Loss: 0.3621 Acc:0.8709\n",
      "\n",
      "test Loss: 1.0677 Acc:0.5240\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "train Loss: 0.4261 Acc:0.8619\n",
      "\n",
      "test Loss: 0.8439 Acc:0.7800\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "train Loss: 0.3863 Acc:0.8659\n",
      "\n",
      "test Loss: 0.9458 Acc:0.5920\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "train Loss: 0.3277 Acc:0.8809\n",
      "\n",
      "test Loss: 1.5174 Acc:0.4440\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "train Loss: 0.4954 Acc:0.8148\n",
      "\n",
      "test Loss: 1.3809 Acc:0.4280\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "train Loss: 0.3506 Acc:0.8939\n",
      "\n",
      "test Loss: 2.2849 Acc:0.4160\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "train Loss: 0.3960 Acc:0.8629\n",
      "\n",
      "test Loss: 1.7379 Acc:0.4560\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "train Loss: 0.3552 Acc:0.8679\n",
      "\n",
      "test Loss: 0.8217 Acc:0.7120\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "train Loss: 0.3041 Acc:0.8869\n",
      "\n",
      "test Loss: 1.3474 Acc:0.4600\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "train Loss: 0.4684 Acc:0.8308\n",
      "\n",
      "test Loss: 1.9084 Acc:0.3760\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "train Loss: 0.3080 Acc:0.8909\n",
      "\n",
      "test Loss: 0.6143 Acc:0.7760\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "train Loss: 0.2125 Acc:0.9279\n",
      "\n",
      "test Loss: 0.9606 Acc:0.6200\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "train Loss: 0.2412 Acc:0.9189\n",
      "\n",
      "test Loss: 1.3464 Acc:0.7400\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "train Loss: 0.2607 Acc:0.9109\n",
      "\n",
      "test Loss: 0.7916 Acc:0.7040\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-503f2484deed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-c6a12a092e07>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fontastic/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in list(model.parameters())[:-1]:\n",
    "        param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "def unfreeze(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = unfreeze(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.2056 Acc:0.9299\n",
      "\n",
      "test Loss: 0.7248 Acc:0.7560\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.1585 Acc:0.9510\n",
      "\n",
      "test Loss: 0.7665 Acc:0.7360\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.4671 Acc:0.8348\n",
      "\n",
      "test Loss: 0.5958 Acc:0.7760\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2925 Acc:0.9009\n",
      "\n",
      "test Loss: 1.8298 Acc:0.5240\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.2961 Acc:0.8919\n",
      "\n",
      "test Loss: 0.7023 Acc:0.7320\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.1882 Acc:0.9389\n",
      "\n",
      "test Loss: 0.7925 Acc:0.7160\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.2375 Acc:0.9339\n",
      "\n",
      "test Loss: 1.0633 Acc:0.6320\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2460 Acc:0.9229\n",
      "\n",
      "test Loss: 0.8348 Acc:0.7440\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1633 Acc:0.9590\n",
      "\n",
      "test Loss: 0.7900 Acc:0.7240\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1624 Acc:0.9499\n",
      "\n",
      "test Loss: 0.2069 Acc:0.9320\n",
      "\n",
      "Training complete in 4.000000m 26s\n",
      "Best val acc: 0.932000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = freeze(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.4360 Acc:0.8488\n",
      "\n",
      "test Loss: 0.6452 Acc:0.8120\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.6208 Acc:0.7718\n",
      "\n",
      "test Loss: 0.6950 Acc:0.7400\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.6747 Acc:0.7698\n",
      "\n",
      "test Loss: 0.6901 Acc:0.7880\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.7271 Acc:0.7738\n",
      "\n",
      "test Loss: 0.8617 Acc:0.7600\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.8535 Acc:0.7638\n",
      "\n",
      "test Loss: 0.9477 Acc:0.7560\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.9515 Acc:0.7608\n",
      "\n",
      "test Loss: 1.0283 Acc:0.7800\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.0515 Acc:0.7638\n",
      "\n",
      "test Loss: 1.1225 Acc:0.7880\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.1577 Acc:0.7618\n",
      "\n",
      "test Loss: 1.1962 Acc:0.7920\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.2224 Acc:0.7668\n",
      "\n",
      "test Loss: 1.2698 Acc:0.7520\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.2784 Acc:0.7608\n",
      "\n",
      "test Loss: 1.3125 Acc:0.7520\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.3330 Acc:0.7247\n",
      "\n",
      "test Loss: 1.3461 Acc:0.7160\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.3632 Acc:0.6977\n",
      "\n",
      "test Loss: 1.3871 Acc:0.6800\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.3911 Acc:0.6767\n",
      "\n",
      "test Loss: 1.4067 Acc:0.6440\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.4107 Acc:0.6316\n",
      "\n",
      "test Loss: 1.4250 Acc:0.6040\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.4260 Acc:0.5986\n",
      "\n",
      "test Loss: 1.4356 Acc:0.5800\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.4374 Acc:0.5626\n",
      "\n",
      "test Loss: 1.4509 Acc:0.5320\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.4460 Acc:0.5335\n",
      "\n",
      "test Loss: 1.4580 Acc:0.5000\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.4520 Acc:0.4825\n",
      "\n",
      "test Loss: 1.4601 Acc:0.4120\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.4576 Acc:0.4244\n",
      "\n",
      "test Loss: 1.4633 Acc:0.4000\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.4597 Acc:0.3874\n",
      "\n",
      "test Loss: 1.4662 Acc:0.3840\n",
      "\n",
      "Training complete in 3.000000m 44s\n",
      "Best val acc: 0.812000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = unfreeze(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.2154 Acc:0.9409\n",
      "\n",
      "test Loss: 2.7387 Acc:0.4560\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.2470 Acc:0.9299\n",
      "\n",
      "test Loss: 5.0905 Acc:0.2440\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.2743 Acc:0.9149\n",
      "\n",
      "test Loss: 1.4203 Acc:0.7240\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2919 Acc:0.9009\n",
      "\n",
      "test Loss: 0.4242 Acc:0.8720\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.2056 Acc:0.9339\n",
      "\n",
      "test Loss: 0.6886 Acc:0.7360\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.2864 Acc:0.8989\n",
      "\n",
      "test Loss: 0.6357 Acc:0.8000\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1982 Acc:0.9499\n",
      "\n",
      "test Loss: 0.7081 Acc:0.7240\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2353 Acc:0.9209\n",
      "\n",
      "test Loss: 1.2819 Acc:0.7320\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1625 Acc:0.9600\n",
      "\n",
      "test Loss: 0.4625 Acc:0.8840\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.1694 Acc:0.9479\n",
      "\n",
      "test Loss: 0.3051 Acc:0.8920\n",
      "\n",
      "Training complete in 4.000000m 25s\n",
      "Best val acc: 0.892000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = freeze(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.2216 Acc:0.6066\n",
      "\n",
      "test Loss: 1.8235 Acc:0.3800\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.5088 Acc:0.4655\n",
      "\n",
      "test Loss: 2.0141 Acc:0.2720\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.4713 Acc:0.4705\n",
      "\n",
      "test Loss: 1.8144 Acc:0.3080\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.4724 Acc:0.4665\n",
      "\n",
      "test Loss: 1.7585 Acc:0.2960\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.4778 Acc:0.4825\n",
      "\n",
      "test Loss: 1.7118 Acc:0.3000\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-c778ec9f35e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-c6a12a092e07>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fontastic/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                     \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = unfreeze(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.5581 Acc:0.8258\n",
      "\n",
      "test Loss: 0.5870 Acc:0.7960\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.2100 Acc:0.9459\n",
      "\n",
      "test Loss: 1.9395 Acc:0.6240\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2179 Acc:0.9329\n",
      "\n",
      "test Loss: 2.5721 Acc:0.4480\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2671 Acc:0.9189\n",
      "\n",
      "test Loss: 5.2829 Acc:0.2560\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1593 Acc:0.9469\n",
      "\n",
      "test Loss: 0.5057 Acc:0.8160\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1671 Acc:0.9510\n",
      "\n",
      "test Loss: 1.0206 Acc:0.6800\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.1762 Acc:0.9459\n",
      "\n",
      "test Loss: 0.5134 Acc:0.8280\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.1633 Acc:0.9520\n",
      "\n",
      "test Loss: 0.9351 Acc:0.7760\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.3058 Acc:0.9129\n",
      "\n",
      "test Loss: 0.9914 Acc:0.7120\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.2375 Acc:0.9279\n",
      "\n",
      "test Loss: 0.6702 Acc:0.8080\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.1556 Acc:0.9499\n",
      "\n",
      "test Loss: 0.4232 Acc:0.8440\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.1210 Acc:0.9670\n",
      "\n",
      "test Loss: 0.3684 Acc:0.8760\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.1243 Acc:0.9610\n",
      "\n",
      "test Loss: 0.2380 Acc:0.9200\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.1047 Acc:0.9780\n",
      "\n",
      "test Loss: 0.2802 Acc:0.9080\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.1983 Acc:0.9319\n",
      "\n",
      "test Loss: 1.4234 Acc:0.6560\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.1351 Acc:0.9690\n",
      "\n",
      "test Loss: 0.2014 Acc:0.9320\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.1081 Acc:0.9720\n",
      "\n",
      "test Loss: 0.2798 Acc:0.9040\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0999 Acc:0.9730\n",
      "\n",
      "test Loss: 0.0695 Acc:0.9920\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.1078 Acc:0.9740\n",
      "\n",
      "test Loss: 0.6682 Acc:0.7280\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.1657 Acc:0.9489\n",
      "\n",
      "test Loss: 0.4406 Acc:0.8680\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.1853 Acc:0.9399\n",
      "\n",
      "test Loss: 0.9064 Acc:0.7400\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.1634 Acc:0.9530\n",
      "\n",
      "test Loss: 0.3259 Acc:0.8880\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.1755 Acc:0.9499\n",
      "\n",
      "test Loss: 0.8395 Acc:0.7440\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.1350 Acc:0.9650\n",
      "\n",
      "test Loss: 0.2404 Acc:0.9240\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0996 Acc:0.9730\n",
      "\n",
      "test Loss: 0.0820 Acc:0.9840\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.1317 Acc:0.9610\n",
      "\n",
      "test Loss: 0.3113 Acc:0.8960\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.1822 Acc:0.9449\n",
      "\n",
      "test Loss: 2.8482 Acc:0.4840\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.1649 Acc:0.9530\n",
      "\n",
      "test Loss: 0.1872 Acc:0.9360\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.1465 Acc:0.9600\n",
      "\n",
      "test Loss: 0.3513 Acc:0.9040\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.1017 Acc:0.9790\n",
      "\n",
      "test Loss: 0.1442 Acc:0.9680\n",
      "\n",
      "Training complete in 13.000000m 14s\n",
      "Best val acc: 0.992000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}, actual: {}'.format(class_names[preds[j]], class_names[labels[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict, os.path.join(experiments_path, 'model_resnet50_tfms.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_model(model_ft, num_images=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

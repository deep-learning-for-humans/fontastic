{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghotham/code/fontastic/venv/lib/python3.6/site-packages/PIL/Image.py:931: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    }
   ],
   "source": [
    "img = load_img('data/roboto/img-roboto-2018-08-02 14:15:46.484655.png')\n",
    "x = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x146387358>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_generator = ImageDataGenerator(rotation_range=90.,\n",
    "                                   featurewise_center=True, \n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='reflect',\n",
    "                                   vertical_flip=True,\n",
    "                                   zoom_range=0.4,\n",
    "                                   featurewise_std_normalization=True,\n",
    "                                   zca_whitening=False,\n",
    "                                   width_shift_range=20,\n",
    "                                   height_shift_range=20,\n",
    "                                   validation_split=0.2, rescale=1./255)\n",
    "\n",
    "def get_batches(path, subset, gen=img_generator, \n",
    "                shuffle=True, batch_size=8, class_mode='categorical'): \n",
    "    return gen.flow_from_directory(path, target_size=(228,228), \n",
    "                                   class_mode=class_mode, shuffle=shuffle, batch_size=batch_size, subset=subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghotham/code/fontastic/venv/lib/python3.6/site-packages/PIL/Image.py:931: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    }
   ],
   "source": [
    "img = load_img('data/roboto/img-roboto-2018-08-02 14:15:46.484655.png')  \n",
    "x = img_to_array(img)  \n",
    "x = x.reshape((1,) + x.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/raghotham/code/fontastic\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preview folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning with Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 603 images belonging to 8 classes.\n",
      "Found 147 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_batches('data/', 'training')\n",
    "val_generator = get_batches('data/', 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghotham/code/fontastic/venv/lib/python3.6/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(include_top=False, input_shape=(228,228,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "m = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='sgd',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_triangular = CyclicLR(base_lr=0.001, max_lr=0.1, mode='triangular', step_size=2*600//batch_size)\n",
    "\n",
    "m.compile(optimizer='sgd' , loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghotham/code/fontastic/venv/lib/python3.6/site-packages/PIL/Image.py:931: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n",
      "/Users/raghotham/code/fontastic/venv/lib/python3.6/site-packages/keras_preprocessing/image.py:988: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/Users/raghotham/code/fontastic/venv/lib/python3.6/site-packages/keras_preprocessing/image.py:996: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/37 [==========>...................] - ETA: 1:49 - loss: 3.7569 - acc: 0.2470"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-bcee0927a17d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclr_triangular\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         validation_steps=140 // batch_size)\n\u001b[0m",
      "\u001b[0;32m~/code/fontastic/venv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fontastic/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fontastic/venv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fontastic/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fontastic/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fontastic/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fontastic/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=600 // batch_size,\n",
    "        epochs=10,\n",
    "        callbacks=[clr_triangular],\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=140 // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlabel('Training Iterations' )\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title(\"CLR - 'triangular' Policy\")\n",
    "plt.plot(clr_triangular.history['iterations'], clr_triangular.history['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
